{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 0\n",
    "# Each one of the datasets has properties which makes\n",
    "# them hard to learn. Motivate which of the three problems is most\n",
    "# difficult for a decision tree algorithm to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONK-1 it is hard to choose a parameter to split between a1 and a2.\n",
    "# Would require a split on all values of a1 and then a split on values of a2 (2 + 3 + 3^2 branches)\n",
    "\n",
    "# MONK-3 the trickiest. In order to evaluate if the statement holds, you always have to check all 6 params.\n",
    "# It is only possible to split the space based on all 6 parameter values. It is hard to compute the information gain\n",
    "# and choose the split parameter, the output(if condition holds or not +/-) of a sample changes depending on the value\n",
    "# of the remaining parameters\n",
    "\n",
    "# MONK-3 has the lowest number of training samples and contains additional noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "# The file dtree.py defines a function entropy which\n",
    "# calculates the entropy of a dataset. Import this file along with the\n",
    "# monks datasets and use it to calculate the entropy of the training\n",
    "# datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../dectrees/python')\n",
    "import monkdata as m\n",
    "import dtree as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of monk1: 1.0\n",
      "Entropy of monk2: 0.957117428264771\n",
      "Entropy of monk3: 0.9998061328047111\n"
     ]
    }
   ],
   "source": [
    "monks = [m.monk1, m.monk2, m.monk3]\n",
    "\n",
    "for idx,monk in enumerate(monks):\n",
    "    print(\"Entropy of monk\" + str(idx+1) + \": \" + str(dt.entropy(monk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 2\n",
    "# Explain entropy for a uniform distribution and a\n",
    "# non-uniform distribution, present some example distributions with\n",
    "# high and low entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Uniform Distribution every element of the sample space is\n",
    "# equally likely to occur/be drawn.\n",
    "# Entropy is a measure of uncertainty. How uncertain are you about the\n",
    "# category/outcome of a sample you would draw from a given dataset\n",
    "\n",
    "# Coin toss/ 2 cards - 2 possibilities, equally likely.\n",
    "# As uncertain as you can be about the outcome of a toss -> max Entropy\n",
    "\n",
    "# In a non-unform distribution some elements are more likely to\n",
    "# occur than others. If you make a random guess/draw, you are more likely\n",
    "# to get one category over the others. \n",
    "\n",
    "# 3 cards - 2 black one red, in a random draw 67% that you pick a black one\n",
    "# 33% red one. Not so uncertain and thus entropy is lower\n",
    "# -2/3 * log(2/3) - 1/3 * log(1/3) = 0.28\n",
    "# -3/4 * log(3/4) - 1/4 * log(1/4) = 0.24\n",
    "# (to show the decrease against 2 red to black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3\n",
    "# Use the function averageGain (defined in dtree.py)\n",
    "# to calculate the expected information gain corresponding to each of\n",
    "# the six attributes. Note that the attributes are represented as\n",
    "# instances of the class Attribute (defined in monkdata.py) which you\n",
    "# can access via m.attributes[0], ..., m.attributes[5]. Based on\n",
    "# the results, which attribute should be used for splitting\n",
    "# the examples at the root node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A1    A2    A3    A4    A5    A6    \n",
      "MONK-1 0.075 0.006 0.005 0.026 0.287 0.001 \n",
      "MONK-2 0.004 0.002 0.001 0.016 0.017 0.006 \n",
      "MONK-3 0.007 0.294 0.001 0.003 0.256 0.007 \n"
     ]
    }
   ],
   "source": [
    "print(\"         \", end='')\n",
    "for attribute in m.attributes:\n",
    "    print(str(attribute) + \"    \", end='')\n",
    "print()\n",
    "\n",
    "for idx, monk in enumerate(monks):\n",
    "    print(\"MONK-\" + str(idx+1) + \" \", end='')\n",
    "    for attribute in m.attributes:\n",
    "        print(\"%.3f\" % dt.averageGain(monk,attribute) + \" \", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best-split attributes\n",
    "# MONK-1: A5\n",
    "# MONK-2: A5\n",
    "# MONK-3: A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 4\n",
    "# For splitting we choose the attribute that maximizes\n",
    "# the information gain, Eq.3. Looking at Eq.3 how does the entropy of\n",
    "# the subsets, S k , look like when the information gain is maximized?\n",
    "# How can we motivate using the information gain as a heuristic for\n",
    "# picking an attribute for splitting? Think about reduction in entropy\n",
    "# after the split and what the entropy implies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we split a dataset on a parameter that maximizes the information gain, \n",
    "# we minimize the entropy of the dataset. The goal is to minimize\n",
    "# the entropy of a dataset, reduce the impurity/order the set.\n",
    "# Therefore infromation gain as a heuristic for choosing split\n",
    "# parameters exactly fits into the idea of ordering of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the monk1 data draw the decision tree up to the first two levels and\n",
    "# assign the majority class of the subsets that resulted from the two splits\n",
    "# to the leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A5(+A4(---)A6(--)A1(--+))\n"
     ]
    }
   ],
   "source": [
    "print(dt.buildTree(m.monk1, m.attributes, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A5+A4---A6--A1--+"
     ]
    }
   ],
   "source": [
    "def buildTreeCustom(dataset, depth):\n",
    "    if (depth > 0):\n",
    "        bestAttr = dt.bestAttribute(dataset, m.attributes)\n",
    "        print(str(bestAttr), end='')\n",
    "        \n",
    "        # Select datasets splits for each value of the bestAttr\n",
    "        splits = []\n",
    "        for value in bestAttr.values:\n",
    "            splits.append(dt.select(dataset, bestAttr, value))\n",
    "                \n",
    "        for split in splits:\n",
    "            # If entropy of the split > 0, the split is impure and we can further split it. Recursive call with reduced depth\n",
    "            if (dt.entropy(split) > 0):\n",
    "                buildTreeCustom(split, depth-1)\n",
    "            else:\n",
    "                print('+' if dt.mostCommon(split) else '-', end='')\n",
    "    else:\n",
    "        print('+' if dt.mostCommon(dataset) else '-', end='')\n",
    "\n",
    "buildTreeCustom(m.monk1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 5\n",
    "# Build the full decision trees for all three Monk datasets using\n",
    "# buildTree. Then, use the function check to measure the performance of the decision tree on both the training and\n",
    "# test datasets. \n",
    "# Compute the train and test set errors for the three Monk datasets\n",
    "# for the full trees. Were your assumptions about the datasets correct?\n",
    "# Explain the results you get for the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONK-1 Training set: 1.0, Test set: 0.8287037037037037\n",
      "MONK-2 Training set: 1.0, Test set: 0.6921296296296297\n",
      "MONK-3 Training set: 1.0, Test set: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "t1 = dt.buildTree(m.monk1, m.attributes)\n",
    "t2 = dt.buildTree(m.monk2, m.attributes)\n",
    "t3 = dt.buildTree(m.monk3, m.attributes)\n",
    "\n",
    "print(\"MONK-1 Training set: \" + str(dt.check(t1, m.monk1)) + \", Test set: \" + str(dt.check(t1, m.monk1test)))\n",
    "print(\"MONK-2 Training set: \" + str(dt.check(t2, m.monk2)) + \", Test set: \" + str(dt.check(t2, m.monk2test)))\n",
    "print(\"MONK-3 Training set: \" + str(dt.check(t3, m.monk3)) + \", Test set: \" + str(dt.check(t3, m.monk3test)))\n",
    "\n",
    "# Assumptions seem to be correct. All samples in the training datasets have been correctly classified.\n",
    "# In the test sets respectively 83%, 69% and 94% correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 0\n",
    "# Each one of the datasets has properties which makes\n",
    "# them hard to learn. Motivate which of the three problems is most\n",
    "# difficult for a decision tree algorithm to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONK-1 it is hard to choose a parameter to split between a1 and a2.\n",
    "# Would require a split on all values of a1 and then a split on values of a2 (2 + 3 + 3^2 branches)\n",
    "\n",
    "# MONK-3 the trickiest. In order to evaluate if the statement holds, you always have to check all 6 params.\n",
    "# It is only possible to split the space based on all 6 parameter values. It is hard to compute the information gain\n",
    "# and choose the split parameter, the output(if condition holds or not +/-) of a sample changes depending on the value\n",
    "# of the remaining parameters\n",
    "\n",
    "# MONK-3 has the lowest number of training samples and contains additional noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "# The file dtree.py defines a function entropy which\n",
    "# calculates the entropy of a dataset. Import this file along with the\n",
    "# monks datasets and use it to calculate the entropy of the training\n",
    "# datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../dectrees/python')\n",
    "import monkdata as m\n",
    "import dtree as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of monk1: 1.0\n",
      "Entropy of monk2: 0.957117428264771\n",
      "Entropy of monk3: 0.9998061328047111\n"
     ]
    }
   ],
   "source": [
    "monks = [m.monk1, m.monk2, m.monk3]\n",
    "\n",
    "for idx,monk in enumerate(monks):\n",
    "    print(\"Entropy of monk\" + str(idx+1) + \": \" + str(dt.entropy(monk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 2\n",
    "# Explain entropy for a uniform distribution and a\n",
    "# non-uniform distribution, present some example distributions with\n",
    "# high and low entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Uniform Distribution every element of the sample space is\n",
    "# equally likely to occur/be drawn.\n",
    "# Entropy is a measure of uncertainty. How uncertain are you about the\n",
    "# category/outcome of a sample you would draw from a given dataset\n",
    "\n",
    "# Coin toss/ 2 cards - 2 possibilities, equally likely.\n",
    "# As uncertain as you can be about the outcome of a toss -> max Entropy\n",
    "\n",
    "# In a non-unform distribution some elements are more likely to\n",
    "# occur than others. If you make a random guess/draw, you are more likely\n",
    "# to get one category over the others. \n",
    "\n",
    "# 3 cards - 2 black one red, in a random draw 67% that you pick a black one\n",
    "# 33% red one. Not so uncertain and thus entropy is lower\n",
    "# -2/3 * log(2/3) - 1/3 * log(1/3) = 0.28\n",
    "# -3/4 * log(3/4) - 1/4 * log(1/4) = 0.24\n",
    "# (to show the decrease against 2 red to black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3\n",
    "# Use the function averageGain (defined in dtree.py)\n",
    "# to calculate the expected information gain corresponding to each of\n",
    "# the six attributes. Note that the attributes are represented as\n",
    "# instances of the class Attribute (defined in monkdata.py) which you\n",
    "# can access via m.attributes[0], ..., m.attributes[5]. Based on\n",
    "# the results, which attribute should be used for splitting\n",
    "# the examples at the root node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A1    A2    A3    A4    A5    A6    \n",
      "MONK-1 0.075 0.006 0.005 0.026 0.287 0.001 \n",
      "MONK-2 0.004 0.002 0.001 0.016 0.017 0.006 \n",
      "MONK-3 0.007 0.294 0.001 0.003 0.256 0.007 \n"
     ]
    }
   ],
   "source": [
    "print(\"         \", end='')\n",
    "for attribute in m.attributes:\n",
    "    print(str(attribute) + \"    \", end='')\n",
    "print()\n",
    "\n",
    "for idx, monk in enumerate(monks):\n",
    "    print(\"MONK-\" + str(idx+1) + \" \", end='')\n",
    "    for attribute in m.attributes:\n",
    "        print(\"%.3f\" % dt.averageGain(monk,attribute) + \" \", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best-split attributes\n",
    "# MONK-1: A5\n",
    "# MONK-2: A5\n",
    "# MONK-3: A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 4\n",
    "# For splitting we choose the attribute that maximizes\n",
    "# the information gain, Eq.3. Looking at Eq.3 how does the entropy of\n",
    "# the subsets, S k , look like when the information gain is maximized?\n",
    "# How can we motivate using the information gain as a heuristic for\n",
    "# picking an attribute for splitting? Think about reduction in entropy\n",
    "# after the split and what the entropy implies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
